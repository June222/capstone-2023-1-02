{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["HycXGSSnj7LW"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUunj32AbuV6","outputId":"8c705735-9efb-4dd5-c7de-479a4b95ad00","executionInfo":{"status":"ok","timestamp":1697040651324,"user_tz":-540,"elapsed":15891,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 코랩에서 구글 드라이브 접근\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torchvision.models.resnet import BasicBlock\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import models, datasets\n","from PIL import Image\n","import pandas as pd\n","import os"],"metadata":{"id":"xM4vGepbg3Id","executionInfo":{"status":"ok","timestamp":1697040659047,"user_tz":-540,"elapsed":7724,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class SteelDataset(Dataset):\n","    def __init__(self, csv_path, img_dir, transform=None):\n","        self.data = pd.read_csv(csv_path)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.img_dir,\n","                                # str(self.data.iloc[idx, 1]),\n","                                self.data.iloc[idx, 0])\n","        image = Image.open(img_name)\n","        # 이미지를 6등분하여 각각 (224, 224)로 리사이즈\n","        img_parts = []\n","        width, height = image.size\n","        crop_size = (width // 3, height // 2)\n","        for i in range(2):\n","            for j in range(3):\n","                left = j * crop_size[0]\n","                upper = i * crop_size[1]\n","                right = left + crop_size[0]\n","                lower = upper + crop_size[1]\n","                img_part = image.crop((left,\n","                                       upper,\n","                                       right,\n","                                       lower,\n","                                       )).resize((224, 224))\n","                img_parts.append(img_part)\n","\n","        label = int(self.data.iloc[idx, 1]) - 1  # 라벨을 0부터 시작하도록 변환\n","        if self.transform:\n","            img_parts = [self.transform(part) for part in img_parts]\n","        return img_parts, label"],"metadata":{"id":"hY30ZcwSg2ur","executionInfo":{"status":"ok","timestamp":1697040659047,"user_tz":-540,"elapsed":7,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 하이퍼파라미터 설정\n","batch_size = 32\n","learning_rate = 0.001\n","num_classes = 4\n","\n","# 데이터 로드 및 전처리\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","train_dataset = SteelDataset(csv_path='/content/drive/MyDrive/졸업과제/severstal-steel-defect-detection/new_train.csv',\n","                              img_dir='/content/drive/MyDrive/졸업과제/severstal-steel-defect-detection/train_images/',\n","                              transform=transform)"],"metadata":{"id":"R4T8QkrfhCSy","executionInfo":{"status":"ok","timestamp":1697040659621,"user_tz":-540,"elapsed":579,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","\n","# 전체 데이터셋의 크기\n","total_size = len(train_dataset)\n","\n","# 각각의 데이터셋 크기 계산\n","train_size = int(0.8 * total_size)\n","val_size = total_size - train_size\n","\n","# 데이터셋을 나누기\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# DataLoader 정의\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"i29Y_v3NLIG6","executionInfo":{"status":"ok","timestamp":1697040659621,"user_tz":-540,"elapsed":5,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class ResNetSteelClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNetSteelClassifier, self).__init__()\n","        self.resnet = models.resnet50(pretrained=True)\n","        num_features = self.resnet.fc.in_features\n","        self.resnet.fc = nn.Linear(num_features, num_classes)\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = ResNetSteelClassifier(num_classes=4).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"tv2xFCMEhoRD","executionInfo":{"status":"ok","timestamp":1697040660878,"user_tz":-540,"elapsed":1261,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7df98d25-344f-4057-f51f-dc36270f6936"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 177MB/s]\n"]}]},{"cell_type":"code","source":["num_epochs = 1\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    with tqdm(train_loader, unit=\"batch\") as t:\n","        for img_parts, labels in t:\n","            optimizer.zero_grad()\n","            outputs = []\n","\n","            for part in img_parts:\n","                # images, labels = images.to(device), labels.to(device)\n","                part = part.to(device)\n","                part_outputs = model(part)\n","                part_outputs = part_outputs.to(device)\n","                outputs.append(part_outputs)\n","\n","            outputs = torch.stack(outputs, dim=1).mean(dim=1)  # 이미지 부분의 출력 평균\n","            labels = labels.to(device)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            t.set_postfix(loss=running_loss / (t.n + 1))\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"],"metadata":{"id":"dtyGfoP0zs9b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0930b206-dfb7-407b-c2ac-85ded82b8f0b","executionInfo":{"status":"ok","timestamp":1697046760798,"user_tz":-540,"elapsed":6094423,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [1:41:34<00:00, 39.07s/batch, loss=0.63]"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Loss: 0.6629\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# 학습된 모델 저장\n","torch.save(model.state_dict(), '/content/drive/MyDrive/졸업과제/모델/ResNet/resnet_50.pth')"],"metadata":{"id":"mn9AMX-OjjHy","executionInfo":{"status":"ok","timestamp":1697046761312,"user_tz":-540,"elapsed":519,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 모델 불러오기\n","loaded_model = ResNetSteelClassifier(num_classes=4).to(device)\n","loaded_model.load_state_dict(torch.load('/content/drive/MyDrive/졸업과제/모델/ResNet/resnet_50.pth'))\n","loaded_model.eval()"],"metadata":{"id":"7smiUG2IaqzA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697046762109,"user_tz":-540,"elapsed":801,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}},"outputId":"c2fd59f4-cf9a-4459-8abd-c7e271b59a65"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNetSteelClassifier(\n","  (resnet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=2048, out_features=4, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 모델 평가\n","preds = []\n","targets = []\n","\n","with torch.no_grad(), tqdm(train_loader, unit=\"batch\") as t:\n","    for img_parts, labels in t:\n","\n","        optimizer.zero_grad()\n","        outputs = []\n","\n","        for part in img_parts:\n","            # images, labels = images.to(device), labels.to(device)\n","            part = part.to(device)\n","            part_outputs = loaded_model(part)\n","            part_outputs = part_outputs.to(device)\n","            outputs.append(part_outputs)\n","\n","        outputs = torch.stack(outputs, dim=1).mean(dim=1)\n","        _, predicted = torch.max(outputs, 1)\n","        targets.extend(labels.cpu().numpy())\n","        preds.extend(predicted.cpu().numpy())\n","        t.set_postfix(accuracy=accuracy_score(targets, preds))\n","\n","# 평가 지표 계산\n","accuracy = accuracy_score(targets, preds)\n","precision = precision_score(targets, preds, average='weighted')\n","recall = recall_score(targets, preds, average='weighted')\n","f1 = f1_score(targets, preds, average='weighted')\n","\n","print()\n","print(\"Train\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")"],"metadata":{"id":"LcKyt7nQdI1m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697048325554,"user_tz":-540,"elapsed":1563455,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}},"outputId":"e2f67fdc-4f66-432e-c255-5c8b8b745545"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 156/156 [26:03<00:00, 10.02s/batch, accuracy=0.819]"]},{"output_type":"stream","name":"stdout","text":["\n","Train\n","Accuracy: 0.8193\n","Precision: 0.7955\n","Recall: 0.8193\n","F1 Score: 0.8014\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# 모델 평가 및 평가 지표 계산 (테스트 데이터)\n","test_preds = []\n","test_targets = []\n","\n","with torch.no_grad(), tqdm(val_loader, unit=\"batch\") as t:\n","    for img_parts, labels in t:\n","\n","\n","        outputs = []\n","\n","        for part in img_parts:\n","            # images, labels = images.to(device), labels.to(device)\n","            part = part.to(device)\n","            part_outputs = loaded_model(part)\n","            part_outputs = part_outputs.to(device)\n","            outputs.append(part_outputs)\n","\n","        outputs = torch.stack(outputs, dim=1).mean(dim=1)\n","        _, predicted = torch.max(outputs, 1)\n","        test_targets.extend(labels.cpu().numpy())\n","        test_preds.extend(predicted.cpu().numpy())\n","        t.set_postfix(test_accuracy=accuracy_score(test_targets, test_preds))\n","\n","# 평가 지표 계산 (테스트 데이터)\n","test_accuracy = accuracy_score(test_targets, test_preds)\n","test_precision = precision_score(test_targets, test_preds, average='weighted')\n","test_recall = recall_score(test_targets, test_preds, average='weighted')\n","test_f1 = f1_score(test_targets, test_preds, average='weighted')\n","\n","print()\n","print(\"Test\")\n","print(f\"Accuracy: {test_accuracy:.4f}\")\n","print(f\"Precision: {test_precision:.4f}\")\n","print(f\"Recall: {test_recall:.4f}\")\n","print(f\"F1 Score: {test_f1:.4f}\")"],"metadata":{"id":"9U8Q8r5cdOV5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697049036615,"user_tz":-540,"elapsed":711065,"user":{"displayName":"지수파띵","userId":"11322133048221709881"}},"outputId":"615c47aa-0420-43d1-ff00-31c6b94a00ec"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 39/39 [11:50<00:00, 18.23s/batch, test_accuracy=0.806]"]},{"output_type":"stream","name":"stdout","text":["\n","Test\n","Accuracy: 0.8061\n","Precision: 0.7906\n","Recall: 0.8061\n","F1 Score: 0.7924\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}