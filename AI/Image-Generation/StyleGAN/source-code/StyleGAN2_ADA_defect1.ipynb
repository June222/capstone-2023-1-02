{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## StyleGAN2 - ADA\n",
        "- 1번 결함 학습 및 fakeimage생성\n",
        "\n",
        "- 참고1 : StyleGAN2-ADA — Official PyTorch implementation\n",
        "https://github.com/NVlabs/stylegan2-ada-pytorch\n",
        "- 참고2 : 강콩콩 https://velog.io/@gtpgg1013/GAN-%EB%95%8C%EB%AC%B8%EC%9D%B4%EC%95%BC-Generative-Models-%ED%95%99%EC%8A%B5%EA%B8%B0-1"
      ],
      "metadata": {
        "id": "tQEkxBMnBx_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vToBhLugTeve",
        "outputId": "5990170a-ead6-4570-eaa1-3a1f121ec726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3Uu0haccibkI",
        "outputId": "531a0174-1720-41b7-a61a-8c3a886f4e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EM_Tg_n8gjf",
        "outputId": "48cd7f50-1bbc-427a-dd1e-d8ba4b5d98b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov  2 06:51:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing"
      ],
      "metadata": {
        "id": "1HkvPIaR7qp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torch==1.13.0+cu116 torchvision==0.14.0+cu116 torchaudio==0.13.0 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "#!pip install torch==1.7.1+cu116 torchvision==0.8.2+cu116 torchaudio==0.7.2 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "#!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
        "#!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
        "\n",
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aze9mf1Jy8e",
        "outputId": "65bb90c4-6803-4c7a-8c9a-016eeef21bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "KCpkQIJd8TEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_save_dir : google drive에 model 저장 path\n",
        "# train_data_dir : 학습에 사용할 data path (directory, not zip)\n",
        "model_save_dir = '/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model'# '/content/drive/MyDrive/GAN_때문이야/model/20221005'\n",
        "train_data_dir = '/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect1_cropped' #'/content/drive/MyDrive/GAN_때문이야/dataset/4'\n"
      ],
      "metadata": {
        "id": "WgitUzqh8HyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "OJDj4Aa4h-GD",
        "outputId": "7869d7b2-70d0-4b13-8d51-0f69bd8f6119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calc_metrics.py            \u001b[0m\u001b[01;34mdefect4_cropped\u001b[0m/     \u001b[01;34mdocs\u001b[0m/         \u001b[01;34m__pycache__\u001b[0m/     \u001b[01;34mtrain_dataset\u001b[0m/\n",
            "\u001b[01;34mdatasets\u001b[0m/                  defect4_cropped.zip  generate.py   README.md        \u001b[01;34mtraining\u001b[0m/\n",
            "dataset_tool.py            defect4.zip          legacy.py     stylegan         train.py\n",
            "defect1.zip                \u001b[01;34mdnnlib\u001b[0m/              LICENSE.txt   \u001b[01;34mstylegan_model\u001b[0m/\n",
            "defect2_preprocessing.zip  Dockerfile           \u001b[01;34mmetrics\u001b[0m/      style_mixing.py\n",
            "defect2.zip                docker_run.sh        projector.py  \u001b[01;34mtorch_utils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wqET_Luv9Gio",
        "outputId": "bdaf9394-bdb4-4e0d-b07a-9e0b0cf6baa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defect1.zip만들기\n",
        "import os\n",
        "\n",
        "# Path\n",
        "train_data_dir = '/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect1_cropped'\n",
        "os.environ['train_data_dir'] = train_data_dir\n",
        "\n",
        "# zip\n",
        "!python dataset_tool.py --source=$train_data_dir --dest=/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwmn2f-Jzbwt",
        "outputId": "5592bef2-fbe7-429f-8ca7-8722a1afc69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 312/312 [00:04<00:00, 73.09it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_dir = '/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model'\n",
        "os.environ['model_save_dir'] = model_save_dir\n",
        "\n",
        "!python train.py --outdir=$model_save_dir --data=/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect1.zip --cfg=auto --gpus=1 --kimg=100 --snap=25 --workers=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raQM2J-79TuF",
        "outputId": "1fd34c32-124d-407f-a27f-cd7967bd5ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 25,\n",
            "  \"network_snapshot_ticks\": 25,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect1.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 3948,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 2,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 100,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": 0.05,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"run_dir\": \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00007-defect1-auto1-kimg100\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00007-defect1-auto1-kimg100\n",
            "Training data:      /content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect1.zip\n",
            "Training duration:  100 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   3948\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "\n",
            "Num images:  3948\n",
            "Image shape: [1, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    263169      -        [16, 1, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    263169      -        [16, 1, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   263169      -        [16, 1, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   263169      -        [16, 1, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   131585      -        [16, 1, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  65793       -        [16, 1, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  32897       -        [16, 1, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23186516    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   128         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24000961    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2023-11-02 09:59:25.833860: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-02 09:59:25.833909: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-02 09:59:25.833934: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-02 09:59:25.841233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-02 09:59:26.886414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 100 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 48s       sec/tick 18.3    sec/kimg 1144.38 maintenance 89.4   cpumem 4.56   gpumem 12.90  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 312.8447311352265}, \"metric\": \"fid50k_full\", \"total_time\": 349.127849817276, \"total_time_str\": \"5m 49s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1698919538.4998782}\n",
            "tick 1     kimg 4.0      time 8m 58s       sec/tick 77.7    sec/kimg 19.44   maintenance 352.1  cpumem 4.95   gpumem 10.21  augment 0.004\n",
            "tick 2     kimg 8.0      time 10m 16s      sec/tick 78.4    sec/kimg 19.61   maintenance 0.0    cpumem 4.95   gpumem 4.71   augment 0.006\n",
            "tick 3     kimg 12.0     time 11m 34s      sec/tick 77.9    sec/kimg 19.47   maintenance 0.0    cpumem 4.95   gpumem 4.71   augment 0.008\n",
            "tick 4     kimg 16.0     time 12m 52s      sec/tick 78.2    sec/kimg 19.56   maintenance 0.0    cpumem 4.95   gpumem 4.71   augment 0.003\n",
            "tick 5     kimg 20.0     time 14m 10s      sec/tick 78.2    sec/kimg 19.54   maintenance 0.0    cpumem 4.95   gpumem 4.71   augment 0.000\n",
            "tick 6     kimg 24.0     time 15m 29s      sec/tick 78.1    sec/kimg 19.53   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 7     kimg 28.0     time 16m 47s      sec/tick 78.0    sec/kimg 19.50   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 8     kimg 32.0     time 18m 05s      sec/tick 78.1    sec/kimg 19.54   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 9     kimg 36.0     time 19m 23s      sec/tick 77.9    sec/kimg 19.48   maintenance 0.2    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 10    kimg 40.0     time 20m 41s      sec/tick 78.2    sec/kimg 19.56   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 11    kimg 44.0     time 21m 59s      sec/tick 77.9    sec/kimg 19.47   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 12    kimg 48.0     time 23m 17s      sec/tick 78.2    sec/kimg 19.56   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 13    kimg 52.0     time 24m 35s      sec/tick 78.1    sec/kimg 19.53   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 14    kimg 56.0     time 25m 54s      sec/tick 78.0    sec/kimg 19.51   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 15    kimg 60.0     time 27m 12s      sec/tick 78.1    sec/kimg 19.52   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 16    kimg 64.0     time 28m 30s      sec/tick 78.6    sec/kimg 19.64   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 17    kimg 68.0     time 29m 49s      sec/tick 78.3    sec/kimg 19.57   maintenance 0.2    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 18    kimg 72.0     time 31m 07s      sec/tick 78.7    sec/kimg 19.67   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 19    kimg 76.0     time 32m 26s      sec/tick 78.3    sec/kimg 19.56   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 20    kimg 80.0     time 33m 44s      sec/tick 78.7    sec/kimg 19.66   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 21    kimg 84.0     time 35m 03s      sec/tick 78.5    sec/kimg 19.62   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 22    kimg 88.0     time 36m 21s      sec/tick 78.1    sec/kimg 19.52   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 23    kimg 92.0     time 37m 39s      sec/tick 78.3    sec/kimg 19.58   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 24    kimg 96.0     time 38m 58s      sec/tick 78.1    sec/kimg 19.53   maintenance 0.0    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "tick 25    kimg 100.0    time 40m 15s      sec/tick 77.8    sec/kimg 19.52   maintenance 0.2    cpumem 4.95   gpumem 4.70   augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 65.90749490943797}, \"metric\": \"fid50k_full\", \"total_time\": 332.8772690296173, \"total_time_str\": \"5m 33s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000100.pkl\", \"timestamp\": 1698921832.862889}\n",
            "\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "fqPCIHUUnjOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# str(list(range(10000)))[1:-1].replace(' ', '')\n",
        "\n",
        "os.environ['sample_nums'] = str(list(range(100)))[1:-1].replace(' ', '')"
      ],
      "metadata": {
        "id": "CFn0IXSR8ToI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정 필요사항\n",
        "# generate.py : line 121\n",
        "# \t\tPIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png') # 주석처리\n",
        "\n",
        "# 아래 내용으로 수정 (indent 주의)\n",
        "        if img.shape[-1] == 3:\n",
        "            PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')\n",
        "        else:\n",
        "            PIL.Image.fromarray(np.squeeze(img[0][:-2].cpu().numpy()), 'L').save(f'{outdir}/seed{seed:04d}.png')"
      ],
      "metadata": {
        "id": "O9f93BeG0sEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed 1~10000 까지 data generation\n",
        "# trunc는 truncation trick의 계수, 0~1 : 0으로 지정하면 모두 같은 얼굴 생성 / 1로 지정하면 모두 다른 이미지 생성\n",
        "\n",
        "!python generate.py --outdir=/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00007-defect1-auto1-kimg100/fakeimages --trunc=1.0 --seeds=$sample_nums --network=/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00007-defect1-auto1-kimg100/network-snapshot-000100.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdAabPms1zE3",
        "outputId": "26515022-8c74-4382-b0c6-2a60a5462f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00007-defect1-auto1-kimg100/network-snapshot-000100.pkl\"...\n",
            "Generating image for seed 0 (0/100) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 1 (1/100) ...\n",
            "Generating image for seed 2 (2/100) ...\n",
            "Generating image for seed 3 (3/100) ...\n",
            "Generating image for seed 4 (4/100) ...\n",
            "Generating image for seed 5 (5/100) ...\n",
            "Generating image for seed 6 (6/100) ...\n",
            "Generating image for seed 7 (7/100) ...\n",
            "Generating image for seed 8 (8/100) ...\n",
            "Generating image for seed 9 (9/100) ...\n",
            "Generating image for seed 10 (10/100) ...\n",
            "Generating image for seed 11 (11/100) ...\n",
            "Generating image for seed 12 (12/100) ...\n",
            "Generating image for seed 13 (13/100) ...\n",
            "Generating image for seed 14 (14/100) ...\n",
            "Generating image for seed 15 (15/100) ...\n",
            "Generating image for seed 16 (16/100) ...\n",
            "Generating image for seed 17 (17/100) ...\n",
            "Generating image for seed 18 (18/100) ...\n",
            "Generating image for seed 19 (19/100) ...\n",
            "Generating image for seed 20 (20/100) ...\n",
            "Generating image for seed 21 (21/100) ...\n",
            "Generating image for seed 22 (22/100) ...\n",
            "Generating image for seed 23 (23/100) ...\n",
            "Generating image for seed 24 (24/100) ...\n",
            "Generating image for seed 25 (25/100) ...\n",
            "Generating image for seed 26 (26/100) ...\n",
            "Generating image for seed 27 (27/100) ...\n",
            "Generating image for seed 28 (28/100) ...\n",
            "Generating image for seed 29 (29/100) ...\n",
            "Generating image for seed 30 (30/100) ...\n",
            "Generating image for seed 31 (31/100) ...\n",
            "Generating image for seed 32 (32/100) ...\n",
            "Generating image for seed 33 (33/100) ...\n",
            "Generating image for seed 34 (34/100) ...\n",
            "Generating image for seed 35 (35/100) ...\n",
            "Generating image for seed 36 (36/100) ...\n",
            "Generating image for seed 37 (37/100) ...\n",
            "Generating image for seed 38 (38/100) ...\n",
            "Generating image for seed 39 (39/100) ...\n",
            "Generating image for seed 40 (40/100) ...\n",
            "Generating image for seed 41 (41/100) ...\n",
            "Generating image for seed 42 (42/100) ...\n",
            "Generating image for seed 43 (43/100) ...\n",
            "Generating image for seed 44 (44/100) ...\n",
            "Generating image for seed 45 (45/100) ...\n",
            "Generating image for seed 46 (46/100) ...\n",
            "Generating image for seed 47 (47/100) ...\n",
            "Generating image for seed 48 (48/100) ...\n",
            "Generating image for seed 49 (49/100) ...\n",
            "Generating image for seed 50 (50/100) ...\n",
            "Generating image for seed 51 (51/100) ...\n",
            "Generating image for seed 52 (52/100) ...\n",
            "Generating image for seed 53 (53/100) ...\n",
            "Generating image for seed 54 (54/100) ...\n",
            "Generating image for seed 55 (55/100) ...\n",
            "Generating image for seed 56 (56/100) ...\n",
            "Generating image for seed 57 (57/100) ...\n",
            "Generating image for seed 58 (58/100) ...\n",
            "Generating image for seed 59 (59/100) ...\n",
            "Generating image for seed 60 (60/100) ...\n",
            "Generating image for seed 61 (61/100) ...\n",
            "Generating image for seed 62 (62/100) ...\n",
            "Generating image for seed 63 (63/100) ...\n",
            "Generating image for seed 64 (64/100) ...\n",
            "Generating image for seed 65 (65/100) ...\n",
            "Generating image for seed 66 (66/100) ...\n",
            "Generating image for seed 67 (67/100) ...\n",
            "Generating image for seed 68 (68/100) ...\n",
            "Generating image for seed 69 (69/100) ...\n",
            "Generating image for seed 70 (70/100) ...\n",
            "Generating image for seed 71 (71/100) ...\n",
            "Generating image for seed 72 (72/100) ...\n",
            "Generating image for seed 73 (73/100) ...\n",
            "Generating image for seed 74 (74/100) ...\n",
            "Generating image for seed 75 (75/100) ...\n",
            "Generating image for seed 76 (76/100) ...\n",
            "Generating image for seed 77 (77/100) ...\n",
            "Generating image for seed 78 (78/100) ...\n",
            "Generating image for seed 79 (79/100) ...\n",
            "Generating image for seed 80 (80/100) ...\n",
            "Generating image for seed 81 (81/100) ...\n",
            "Generating image for seed 82 (82/100) ...\n",
            "Generating image for seed 83 (83/100) ...\n",
            "Generating image for seed 84 (84/100) ...\n",
            "Generating image for seed 85 (85/100) ...\n",
            "Generating image for seed 86 (86/100) ...\n",
            "Generating image for seed 87 (87/100) ...\n",
            "Generating image for seed 88 (88/100) ...\n",
            "Generating image for seed 89 (89/100) ...\n",
            "Generating image for seed 90 (90/100) ...\n",
            "Generating image for seed 91 (91/100) ...\n",
            "Generating image for seed 92 (92/100) ...\n",
            "Generating image for seed 93 (93/100) ...\n",
            "Generating image for seed 94 (94/100) ...\n",
            "Generating image for seed 95 (95/100) ...\n",
            "Generating image for seed 96 (96/100) ...\n",
            "Generating image for seed 97 (97/100) ...\n",
            "Generating image for seed 98 (98/100) ...\n",
            "Generating image for seed 99 (99/100) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#python train.py --outdir=/training-runs --data=/my-image-folder --resume=~/training-runs/<NAME>/network-snapshot-000100.pkl\n",
        "\n",
        "!python train.py --outdir=$model_save_dir --data=/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect2_preprocessing.zip --resume=/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00005-defect2_preprocessing-auto1-kimg100/network-snapshot-000100.pkl --cfg=auto --gpus=1 --kimg=400 --snap=25 --workers=2"
      ],
      "metadata": {
        "id": "CblrrLCavFLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d34d82-d927-497c-9abf-87877cc5facd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 25,\n",
            "  \"network_snapshot_ticks\": 25,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect2_preprocessing.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 312,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 2,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 400,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00005-defect2_preprocessing-auto1-kimg100/network-snapshot-000100.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00006-defect2_preprocessing-auto1-kimg400-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   /content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00006-defect2_preprocessing-auto1-kimg400-resumecustom\n",
            "Training data:      /content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/defect2_preprocessing.zip\n",
            "Training duration:  400 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   312\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "\n",
            "Num images:  312\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/stylegan/stylegan2-ada-pytorch-main/stylegan_model/00005-defect2_preprocessing-auto1-kimg100/network-snapshot-000100.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           262656      -        [16, 512]            float32 \n",
            "mapping.fc1           262656      -        [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 23191522    175568   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2023-11-02 08:04:47.298696: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-02 08:04:47.298750: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-02 08:04:47.298781: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-02 08:04:47.306680: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-02 08:04:48.417359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 400 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 44s          sec/tick 15.9    sec/kimg 993.21  maintenance 27.6   cpumem 5.04   gpumem 12.97  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": -3.504353730807743e+95}, \"metric\": \"fid50k_full\", \"total_time\": 346.8482666015625, \"total_time_str\": \"5m 47s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1698912665.9976277}\n",
            "tick 1     kimg 4.0      time 8m 04s       sec/tick 79.7    sec/kimg 19.94   maintenance 360.5  cpumem 5.46   gpumem 10.23  augment 0.037\n",
            "tick 2     kimg 8.0      time 9m 24s       sec/tick 80.2    sec/kimg 20.05   maintenance 0.0    cpumem 5.46   gpumem 4.84   augment 0.075\n",
            "tick 3     kimg 12.0     time 10m 44s      sec/tick 79.9    sec/kimg 19.97   maintenance 0.0    cpumem 5.46   gpumem 4.93   augment 0.109\n",
            "tick 4     kimg 16.0     time 12m 04s      sec/tick 80.3    sec/kimg 20.08   maintenance 0.0    cpumem 5.46   gpumem 4.89   augment 0.146\n",
            "tick 5     kimg 20.0     time 13m 25s      sec/tick 80.2    sec/kimg 20.06   maintenance 0.0    cpumem 5.46   gpumem 4.93   augment 0.174\n",
            "tick 6     kimg 24.0     time 14m 45s      sec/tick 80.2    sec/kimg 20.05   maintenance 0.0    cpumem 5.46   gpumem 4.90   augment 0.198\n",
            "tick 7     kimg 28.0     time 16m 05s      sec/tick 80.2    sec/kimg 20.06   maintenance 0.0    cpumem 5.46   gpumem 4.94   augment 0.214\n",
            "tick 8     kimg 32.0     time 17m 25s      sec/tick 80.3    sec/kimg 20.08   maintenance 0.0    cpumem 5.46   gpumem 4.92   augment 0.221\n",
            "tick 9     kimg 36.0     time 18m 46s      sec/tick 80.1    sec/kimg 20.04   maintenance 0.2    cpumem 5.46   gpumem 4.94   augment 0.238\n",
            "tick 10    kimg 40.0     time 20m 06s      sec/tick 80.5    sec/kimg 20.13   maintenance 0.0    cpumem 5.46   gpumem 4.93   augment 0.259\n",
            "tick 11    kimg 44.0     time 21m 26s      sec/tick 80.2    sec/kimg 20.04   maintenance 0.0    cpumem 5.46   gpumem 4.93   augment 0.255\n",
            "tick 12    kimg 48.0     time 22m 47s      sec/tick 80.5    sec/kimg 20.13   maintenance 0.0    cpumem 5.46   gpumem 4.93   augment 0.257\n",
            "tick 13    kimg 52.0     time 24m 07s      sec/tick 80.5    sec/kimg 20.12   maintenance 0.0    cpumem 5.46   gpumem 4.92   augment 0.269\n",
            "tick 14    kimg 56.0     time 25m 28s      sec/tick 80.4    sec/kimg 20.09   maintenance 0.0    cpumem 5.46   gpumem 4.93   augment 0.279\n",
            "tick 15    kimg 60.0     time 26m 48s      sec/tick 80.3    sec/kimg 20.08   maintenance 0.0    cpumem 5.46   gpumem 4.92   augment 0.290\n",
            "tick 16    kimg 64.0     time 28m 09s      sec/tick 80.4    sec/kimg 20.11   maintenance 0.0    cpumem 5.46   gpumem 4.92   augment 0.325\n",
            "tick 17    kimg 68.0     time 29m 29s      sec/tick 80.2    sec/kimg 20.05   maintenance 0.2    cpumem 5.46   gpumem 4.96   augment 0.358\n",
            "tick 18    kimg 72.0     time 30m 50s      sec/tick 80.6    sec/kimg 20.16   maintenance 0.0    cpumem 5.46   gpumem 4.96   augment 0.392\n",
            "tick 19    kimg 76.0     time 32m 10s      sec/tick 80.3    sec/kimg 20.07   maintenance 0.0    cpumem 5.46   gpumem 4.94   augment 0.425\n",
            "tick 20    kimg 80.0     time 33m 31s      sec/tick 80.7    sec/kimg 20.18   maintenance 0.0    cpumem 5.46   gpumem 4.97   augment 0.451\n",
            "tick 21    kimg 84.0     time 34m 51s      sec/tick 80.5    sec/kimg 20.13   maintenance 0.0    cpumem 5.46   gpumem 4.94   augment 0.474\n",
            "tick 22    kimg 88.0     time 36m 12s      sec/tick 80.5    sec/kimg 20.12   maintenance 0.0    cpumem 5.46   gpumem 4.94   augment 0.493\n",
            "tick 23    kimg 92.0     time 37m 32s      sec/tick 80.5    sec/kimg 20.12   maintenance 0.0    cpumem 5.46   gpumem 4.99   augment 0.520\n",
            "tick 24    kimg 96.0     time 38m 53s      sec/tick 80.6    sec/kimg 20.14   maintenance 0.0    cpumem 5.46   gpumem 4.96   augment 0.547\n",
            "tick 25    kimg 100.0    time 40m 13s      sec/tick 80.4    sec/kimg 20.10   maintenance 0.2    cpumem 5.46   gpumem 4.97   augment 0.570\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 1.0576895500643978e+124}, \"metric\": \"fid50k_full\", \"total_time\": 333.4444808959961, \"total_time_str\": \"5m 33s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000100.pkl\", \"timestamp\": 1698915015.335781}\n",
            "tick 26    kimg 104.0    time 47m 14s      sec/tick 80.7    sec/kimg 20.17   maintenance 339.9  cpumem 5.47   gpumem 4.97   augment 0.576\n",
            "tick 27    kimg 108.0    time 48m 34s      sec/tick 80.4    sec/kimg 20.10   maintenance 0.0    cpumem 5.47   gpumem 4.97   augment 0.588\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MiEY5fGmDOm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}