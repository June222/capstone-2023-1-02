{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suM40TlO65Ey",
        "outputId": "4549d295-1c80-4f68-cd58-0a46a7a381d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "철강데이터가 위치한 폴더로 이동"
      ],
      "metadata": {
        "id": "3c7x-gwurXex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_2nXKrw66X5",
        "outputId": "2838f916-1a67-440a-c968-a54ffe1ed095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/SteelData/severstal-steel-defect-detection\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/SteelData/severstal-steel-defect-detection/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRSZoZeP68oC",
        "outputId": "2178fdca-ba2e-40e9-b23b-d59883f96aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcrop_defect2\u001b[0m/  \u001b[01;34mmodel_state_dict\u001b[0m/      \u001b[01;34mtest_images\u001b[0m/  \u001b[01;34mtrain_image\u001b[0m/\n",
            "\u001b[01;34mdataset\u001b[0m/       new_train.csv          \u001b[01;34mtrain\u001b[0m/        \u001b[01;34mtrain_log\u001b[0m/\n",
            "\u001b[01;34mdefect_class\u001b[0m/  sample_submission.csv  train.csv\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVfbEjjc6-CZ"
      },
      "source": [
        "train폴더의 전체 이미지 파일 중 'train.csv' 파일의 ClassId가 i인 이미지만 추출한다.\n",
        "\n",
        "단, 한 이미지에 여러 클래스가 있는 경우 학습이 제대로 되지 않기 때문에 gropby를 통해 같은 ImageId를 가진 파일 중 오로지 ClassId i만을 가진 이미지 파일만 추출하게 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pl0M0tG6uoQ",
        "outputId": "18e0a61d-64ef-4958-8b34-5de9d570d63a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-06d08e8c9475>:27: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for image_filename, class_ids in grouped_data.iteritems():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 클래스의 이미지를 defect_class/defect1/ 디렉토리로 복사했습니다.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file = 'train.csv'\n",
        "\n",
        "# 이미지 파일이 있는 디렉토리 경로\n",
        "image_dir = 'train/train_images/'\n",
        "\n",
        "# 클래스 ID로 필터링\n",
        "class_id_to_extract = 1\n",
        "\n",
        "# 결과를 저장할 디렉토리 경로\n",
        "output_dir = 'defect_class/defect1/'\n",
        "\n",
        "# 결과 디렉토리 생성\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# CSV 파일 읽기\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# ImageId별로 그룹화하고 각 그룹에서 ClassId 값들의 집합 생성\n",
        "grouped_data = data.groupby('ImageId')['ClassId'].apply(set)\n",
        "\n",
        "for image_filename, class_ids in grouped_data.iteritems():\n",
        "    # 해당 이미지가 오직 class_id_to_extract 결함만 가진 경우 복사\n",
        "    if class_ids == {class_id_to_extract}:\n",
        "        src_path = os.path.join(image_dir, image_filename)\n",
        "        dst_path = os.path.join(output_dir, image_filename)\n",
        "\n",
        "        # 이미지 파일 복사\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(f\"{class_id_to_extract} 클래스의 이미지를 {output_dir} 디렉토리로 복사했습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnA3stPA-yK2"
      },
      "source": [
        "CSV파일에서 중복 클래스를 필터로 제거하면 아래 코드로 돌려도 된다.\n",
        "아래 코드가 실행시간이 훨씬 짧다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JNAk8i93-e7Q",
        "outputId": "3d2df3c7-7805-4850-832e-af768c57200a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 클래스의 이미지를 defect_class/defect3/ 디렉토리로 복사했습니다.\n"
          ]
        }
      ],
      "source": [
        "# 전체 이미지에서 결함1번 클래스 이미지 추출\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file = 'new_train.csv'\n",
        "\n",
        "# 이미지 파일이 있는 디렉토리 경로\n",
        "image_dir = 'train/train_images/'\n",
        "\n",
        "# 클래스 ID로 필터링\n",
        "class_id_to_extract = 3\n",
        "\n",
        "# 결과를 저장할 디렉토리 경로\n",
        "output_dir = 'defect_class/defect3/'\n",
        "\n",
        "# 결과 디렉토리 생성\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# CSV 파일 읽기\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# classID가 2인 이미지 파일 복사\n",
        "for index, row in data.iterrows():\n",
        "    if row['ClassId'] == class_id_to_extract:\n",
        "        image_filename = row['ImageId']  # 이미지 파일 이름\n",
        "        src_path = os.path.join(image_dir, image_filename)\n",
        "        dst_path = os.path.join(output_dir, image_filename)\n",
        "\n",
        "        # 이미지 파일 복사\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "print(f\"{class_id_to_extract} 클래스의 이미지를 {output_dir} 디렉토리로 복사했습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1msFb4U28Fg7"
      },
      "source": [
        "1600*256의 철강이미지 중 많은 부분이 검은색 배경을 가지고 있다. 학습을 위해 resize할때 유의미한 부분이 유실되지 않도록 6등분하고, 이 중 검은배경만 있는 이미지는 제외하고 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiB9GZj78Fq1"
      },
      "outputs": [],
      "source": [
        "#6등분 후 검은배경만 있는 이미지 제외하고 저장\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def divide_and_save_images(img_dir, save_dir):\n",
        "    image_names = os.listdir(img_dir)\n",
        "    threshold = 10  # 검정이미지로 판별할 임계값을 설정한다.\n",
        "\n",
        "    for idx in range(len(image_names)):\n",
        "        img_name = os.path.join(img_dir, image_names[idx])\n",
        "        image = Image.open(img_name).convert('L') #grayscale로 이미지를 불러온다.\n",
        "\n",
        "        # 이미지를 가로로 6등분하여 각각 (256, 256)로 리사이즈\n",
        "        width, height = image.size\n",
        "        part_width = width // 6\n",
        "\n",
        "        for i in range(6):\n",
        "            left = i * part_width\n",
        "            right = left + part_width\n",
        "\n",
        "            img_part= image.crop((left, 0,right ,height)).resize((256 ,256))\n",
        "\n",
        "            # 임계값보다 높은 이미지만 저장한다. -> 임계값 보다 낮은 이미지는 검정 이미지로 판별해 저장하지 않는다.\n",
        "            if np.array(img_part).mean() > threshold:\n",
        "                img_part.save(os.path.join(save_dir, f\"{image_names[idx].split('.')[0]}_{i}.jpg\"))\n",
        "\n",
        "divide_and_save_images('defect_class/defect3', 'defect_class/crop_defect3/defect3_cropped')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X19ns9IL633p"
      },
      "source": [
        "PGGAN 학습을 위한 데이터 전처리.\n",
        "\n",
        "trian : 학습과 val : 검증데이터로 나눈다. 아래는 8:2로 기본 설정되어 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxMN_0de8BDC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 원본 이미지가 저장된 디렉토리\n",
        "src_dir = \"dataset/defect2\"\n",
        "\n",
        "# 훈련 세트와 검증 세트가 저장될 디렉토리\n",
        "train_dir = \"dataset/train/defect2\"\n",
        "val_dir = \"dataset/val/defect2\"\n",
        "\n",
        "# 원본 이미지 파일 리스트 생성\n",
        "file_list = os.listdir(src_dir)\n",
        "\n",
        "# 파일 리스트를 훈련 리스트와 검증 리스트로 분할 (비율 8:2)\n",
        "train_list, val_list = train_test_split(file_list, test_size=0.2)\n",
        "\n",
        "# 각각의 리스트에 대한 파일을 train과 val디렉터리 내 defect폴더로 이동\n",
        "\n",
        "for file_name in train_list:\n",
        "    shutil.copy(os.path.join(src_dir, file_name), os.path.join(train_dir, file_name))\n",
        "\n",
        "for file_name in val_list:\n",
        "    shutil.copy(os.path.join(src_dir, file_name), os.path.join(val_dir, file_name))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}